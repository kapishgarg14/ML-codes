{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:06:22.794157Z","iopub.execute_input":"2021-10-07T11:06:22.794452Z","iopub.status.idle":"2021-10-07T11:06:22.798852Z","shell.execute_reply.started":"2021-10-07T11:06:22.794417Z","shell.execute_reply":"2021-10-07T11:06:22.797895Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data = load_breast_cancer()\n\ndata_df = pd.DataFrame(data.data, columns=data.feature_names)\ndata_df['target'] = pd.Series(data.target)\ndataset = data_df\n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:06:50.694572Z","iopub.execute_input":"2021-10-07T11:06:50.694884Z","iopub.status.idle":"2021-10-07T11:06:50.744675Z","shell.execute_reply.started":"2021-10-07T11:06:50.694851Z","shell.execute_reply":"2021-10-07T11:06:50.743546Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# features or attributes\n\nfeatures = dataset.columns[:30]\nprint(\"feature labels : \")\nprint(list(features))\n\n\n# replace missing field by mean of attribute\n\nmeans = {}\nfor feature in features:\n    means[feature] = train_df[feature].mean()\n    train_df[feature].fillna(means[feature] , inplace = True)\n    \ntrain_df['target'].fillna(0, inplace = True)\n\n#function to get hold out test set\n\nfrom random import randrange, seed\n\ndef get_hold_out(dataset, train_size):\n    train = pd.DataFrame(columns = dataset.columns)\n    test = dataset.copy()\n    while len(train) < train_size:\n        index = randrange(int(len(test)))\n        row = test.iloc[index]\n        test.drop([index], axis = 0, inplace = True)\n        train.loc[len(train.index)] = row\n        test.index = range(len(test))\n    return train, test\n\nseed(1)\ntrain_df, test_df = get_hold_out(dataset, 400)\n\nprint()\nprint(\"train data size : \", len(train_df))\nprint(\"test data size : \", len(test_df))\n\ntrain_df.isnull().values.any()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:58:03.399732Z","iopub.execute_input":"2021-10-07T11:58:03.400529Z","iopub.status.idle":"2021-10-07T11:58:04.312768Z","shell.execute_reply.started":"2021-10-07T11:58:03.400483Z","shell.execute_reply":"2021-10-07T11:58:04.311868Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\n\n\ny = train_df.target.copy()\nX = train_df.drop('target', axis = 1)\n\nlr = LogisticRegression(solver = 'liblinear')\nresults = cross_validate(lr, X, y, scoring = ('neg_log_loss'), cv = 5)\n\nvalidation_scores = -1*results['test_score']\nprint(\"Logistic Regression without regularizations\")\nprint('Loss for each fold: ',validation_scores)\nprint('Mean Loss: ',validation_scores.mean())\n\nlr_score = validation_scores.mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:58:07.865234Z","iopub.execute_input":"2021-10-07T11:58:07.865560Z","iopub.status.idle":"2021-10-07T11:58:07.926898Z","shell.execute_reply.started":"2021-10-07T11:58:07.865528Z","shell.execute_reply":"2021-10-07T11:58:07.925867Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"l1 = LogisticRegression(penalty = 'l1', solver = 'liblinear')\nresults = cross_validate(l1, X, y, scoring = ('neg_log_loss'), cv = 5)\n\nvalidation_scores = -1 * results['test_score']\nprint(\"Logistic Regression with L1 regularization\")\nprint('Loss for each fold: ',validation_scores)\nprint('Mean Loss: ',validation_scores.mean())\n\nl1_score = validation_scores.mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:58:08.485306Z","iopub.execute_input":"2021-10-07T11:58:08.485586Z","iopub.status.idle":"2021-10-07T11:58:09.051054Z","shell.execute_reply.started":"2021-10-07T11:58:08.485560Z","shell.execute_reply":"2021-10-07T11:58:09.050002Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"l2 = LogisticRegression(penalty = 'l2',  solver = 'liblinear')\nresults = cross_validate(l2, X, y, scoring = ('neg_log_loss'), cv = 5)\n\nvalidation_scores = -1 * results['test_score']\nprint(\"Logistic Regression with L2 regularization\")\nprint('Loss for each fold: ',validation_scores)\nprint('Mean Loss: ',validation_scores.mean())\n\nl2_score = validation_scores.mean()","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:58:09.402840Z","iopub.execute_input":"2021-10-07T11:58:09.403164Z","iopub.status.idle":"2021-10-07T11:58:09.460450Z","shell.execute_reply.started":"2021-10-07T11:58:09.403120Z","shell.execute_reply":"2021-10-07T11:58:09.459565Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"markdown","source":"Logistic Regression with L1 penalty has minimum loss hence it is picked for further tuning\n","metadata":{}},{"cell_type":"code","source":"\n# fill missing values in hold out set first\nfor feature in features:\n    test_df[feature] = test_df[feature].fillna(means[feature])\ny_test = test_df['target']\ny_test.fillna(0, inplace = True)\ntest_df = test_df.drop('target', axis = 1)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:58:14.641214Z","iopub.execute_input":"2021-10-07T11:58:14.641496Z","iopub.status.idle":"2021-10-07T11:58:14.665053Z","shell.execute_reply.started":"2021-10-07T11:58:14.641468Z","shell.execute_reply":"2021-10-07T11:58:14.664139Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\n\ny = np.array(y)\ny = np.reshape(y,X.shape[0])\ny_test = np.array(y_test)\ny_test = np.reshape(y_test, (test_df.shape[0],))\nl2.fit(X,y)\n\nbase_probs = [0 for _ in range(len(y_test))]\npreds = l2.predict_proba(test_df)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-10-07T11:58:25.308789Z","iopub.execute_input":"2021-10-07T11:58:25.309094Z","iopub.status.idle":"2021-10-07T11:58:25.324975Z","shell.execute_reply.started":"2021-10-07T11:58:25.309052Z","shell.execute_reply":"2021-10-07T11:58:25.323827Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"base_fpr, base_tpr, thresh1 = roc_curve(y_test, base_probs)\nlog_fpr, log_tpr, thresh2 = roc_curve(y_test, preds)\n\nbase_auc = roc_auc_score(y_test, base_probs)\nlog_auc = roc_auc_score(y_test, preds)\n\nplt.plot(base_fpr, base_tpr, linestyle='--', label='Random predictions')\nplt.plot(log_fpr, log_tpr, marker='.', label='Model')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.title('ROC CURVE')\nplt.show()\n\nprint(\"AUC value for random predictions = \"+str(base_auc))\nprint(\"AUC value for model's predictions = \"+str(log_auc))","metadata":{"execution":{"iopub.status.busy":"2021-10-07T12:00:02.968012Z","iopub.execute_input":"2021-10-07T12:00:02.968364Z","iopub.status.idle":"2021-10-07T12:00:03.163100Z","shell.execute_reply.started":"2021-10-07T12:00:02.968328Z","shell.execute_reply":"2021-10-07T12:00:03.162041Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# tuning the threshold\n\noptimal_idx = np.argmax(log_tpr - log_fpr)\noptimal_thresh = thresh2[optimal_idx]\nprint(\"optimal value of threshold based on ROC curve =\",optimal_thresh)","metadata":{"execution":{"iopub.status.busy":"2021-10-07T12:00:59.987147Z","iopub.execute_input":"2021-10-07T12:00:59.988252Z","iopub.status.idle":"2021-10-07T12:00:59.993539Z","shell.execute_reply.started":"2021-10-07T12:00:59.988209Z","shell.execute_reply":"2021-10-07T12:00:59.992956Z"},"trusted":true},"execution_count":114,"outputs":[]}]}