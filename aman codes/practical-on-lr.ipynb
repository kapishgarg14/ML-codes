{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing libraries to handle csv data\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-06T05:02:56.321539Z","iopub.execute_input":"2021-10-06T05:02:56.322266Z","iopub.status.idle":"2021-10-06T05:02:56.327255Z","shell.execute_reply.started":"2021-10-06T05:02:56.322216Z","shell.execute_reply":"2021-10-06T05:02:56.326144Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#reading dataset into a dataframe\n\ndataset = pd.read_csv(\"../input/amsterdam-house-price-prediction/HousingPrices-Amsterdam-August-2021.csv\")\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T04:59:07.728787Z","iopub.execute_input":"2021-10-06T04:59:07.729079Z","iopub.status.idle":"2021-10-06T04:59:07.769716Z","shell.execute_reply.started":"2021-10-06T04:59:07.729048Z","shell.execute_reply":"2021-10-06T04:59:07.768994Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#dropping column that contain text data and filling NA values with mean\n\ndataset = dataset.loc[:,['Price','Area','Room']]\nmean_price = dataset['Price'].mean()\nmean_area = dataset['Area'].mean()\nmean_room = dataset['Room'].mean()\n\ndataset['Price'].fillna(value = mean_price, inplace = True)\ndataset['Area'].fillna(value = mean_area, inplace = True)\ndataset['Room'].fillna(value = mean_room, inplace = True)\n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T04:59:12.575319Z","iopub.execute_input":"2021-10-06T04:59:12.575632Z","iopub.status.idle":"2021-10-06T04:59:12.598722Z","shell.execute_reply.started":"2021-10-06T04:59:12.575599Z","shell.execute_reply":"2021-10-06T04:59:12.597862Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#converting dataframe to np array, shuffling data.\nX = dataset.loc[:,['Area','Room']].to_numpy()\nY = dataset.loc[:,['Price']].to_numpy()\n\ntemp = list(zip(X,Y))\nnp.random.shuffle(temp)\nX,Y = zip(*temp)\n\nX = np.array(X)\nY = np.array(Y)\nY = Y.reshape((len(Y),1))\n\nprint(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:00:24.742221Z","iopub.execute_input":"2021-10-06T05:00:24.742633Z","iopub.status.idle":"2021-10-06T05:00:24.755349Z","shell.execute_reply.started":"2021-10-06T05:00:24.742600Z","shell.execute_reply":"2021-10-06T05:00:24.754268Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#plotting area vs price\nplt.scatter(X[:,0],Y)\nplt.xlabel(\"area\")\nplt.ylabel(\"price\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:08:17.339430Z","iopub.execute_input":"2021-10-06T05:08:17.339733Z","iopub.status.idle":"2021-10-06T05:08:17.550856Z","shell.execute_reply.started":"2021-10-06T05:08:17.339680Z","shell.execute_reply":"2021-10-06T05:08:17.550006Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#plotting number of rooms vs price\nplt.scatter(X[:,1],Y)\nplt.xlabel(\"number of rooms\")\nplt.ylabel(\"price\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:08:42.658303Z","iopub.execute_input":"2021-10-06T05:08:42.658569Z","iopub.status.idle":"2021-10-06T05:08:42.870600Z","shell.execute_reply.started":"2021-10-06T05:08:42.658541Z","shell.execute_reply":"2021-10-06T05:08:42.869824Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"X = X/np.linalg.norm(X)\nY = Y/np.linalg.norm(Y)","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:48:21.442625Z","iopub.execute_input":"2021-10-06T05:48:21.442953Z","iopub.status.idle":"2021-10-06T05:48:21.448284Z","shell.execute_reply.started":"2021-10-06T05:48:21.442923Z","shell.execute_reply":"2021-10-06T05:48:21.447399Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#function for calculating mean squared error\n\ndef MSE(y, y_pred):\n    error = 0.0\n    for i in range(len(y)):\n        error += (y[i] - y_pred[i])**2/len(y)\n    return error\n\n#function for evaluating mean percentage error\n\ndef MPE(y, y_pred):\n    error = 0.0\n    for i in range(len(y)):\n        if y[i] != 0: \n            error += abs(y[i] - y_pred[i])/y[i]\n    error = error/len(y)\n    return error\n\n#function to calculate R squared metric  \n\ndef RSquared(y, y_pred):\n    ss_res = np.sum((y - y_pred)**2)\n    ss_tot = np.sum((y - np.mean(y))**2)\n    r2 = 1 - (ss_res/ss_tot)\n    return r2\n\n#function to calculate adjusted R squared metric\n\ndef RSquaredAdjusted(y, y_pred, m):\n    # m is number of features\n    \n    r2 = RSquared(y, y_pred)\n    n = y.shape[0]\n    r2_ad = 1 - ((1 - r2)*(n - 1)/(n - m - 1))\n    return r2_ad\n\ndef test(x_test, y_test, weights, bias):\n    y_pred = np.dot(x_test, weights) + bias\n    mse = MSE(y_test, y_pred)\n    mpe = MPE(y_test, y_pred)\n    r2 = RSquared(y_test, y_pred)\n    r2_ad = RSquaredAdjusted(y_test, y_pred, x_test.shape[1])\n    #print(f\"MSE : {mse}, MPE : {mpe}, R Squared : {r2}, R Squared Adjusted : {r2_ad}\")\n    return [mse,mpe,r2,r2_ad]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T06:04:28.220954Z","iopub.execute_input":"2021-10-06T06:04:28.221310Z","iopub.status.idle":"2021-10-06T06:04:28.233237Z","shell.execute_reply.started":"2021-10-06T06:04:28.221277Z","shell.execute_reply":"2021-10-06T06:04:28.232315Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def fit(x_train, y_train, learning_rate = 0.0001, num_iter = 10000):\n    weights = np.zeros((x_train.shape[1],1))\n    bias = 0\n    \n    for i in range(num_iter):\n        #values predicted by model\n        y_pred = np.dot(x_train, weights) + bias\n\n        #derivatives for gradient descent\n        del_weights = (1/x_train.shape[0])*(2*np.dot(x_train.T,(y_pred - y_train)))\n        del_bias = (1/x_train.shape[0])*(2*np.sum(y_pred - y_train))\n        \n        #updating value of weights and bias\n        weights -=  learning_rate * del_weights\n        bias -= learning_rate * del_bias\n    \n    return weights,bias\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:41:14.664360Z","iopub.execute_input":"2021-10-06T05:41:14.665300Z","iopub.status.idle":"2021-10-06T05:41:14.673349Z","shell.execute_reply.started":"2021-10-06T05:41:14.665245Z","shell.execute_reply":"2021-10-06T05:41:14.672688Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_ridge(x_train, y_train, learning_rate = 0.0001, num_iter = 10000, Lambda = 10):\n    weights = np.zeros((x_train.shape[1],1))\n    bias = 0\n    \n    for i in range(num_iter):\n        #values predicted by model\n        y_pred = np.dot(x_train, weights) + bias\n\n        #derivatives for gradient descent\n        del_weights = (1/x_train.shape[0])*(2*np.dot(x_train.T,(y_pred - y_train))) + (Lambda/x_train.shape[0])*weights\n        del_bias = (1/x_train.shape[0])*(2*np.sum(y_pred - y_train))\n        \n        #updating value of weights and bias\n        weights -=  learning_rate * del_weights\n        bias -= learning_rate * del_bias\n        \n    return weights,bias\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:41:19.451794Z","iopub.execute_input":"2021-10-06T05:41:19.452463Z","iopub.status.idle":"2021-10-06T05:41:19.461214Z","shell.execute_reply.started":"2021-10-06T05:41:19.452419Z","shell.execute_reply":"2021-10-06T05:41:19.460217Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def fit_lasso(x_train, y_train, learning_rate = 0.0001, num_iter = 10000, Lambda = 10):\n    weights = np.zeros((x_train.shape[1],1))\n    bias = 0\n    \n    for i in range(num_iter):\n        #values predicted by model\n        y_pred = np.dot(x_train, weights) + bias\n\n        #derivatives for gradient descent\n        del_weights = (1/x_train.shape[0])*(2*np.dot(x_train.T,(y_pred - y_train)))\n        del_bias = (1/x_train.shape[0])*(2*np.sum(y_pred - y_train))\n        \n        #adding penalty on weights\n        for j in range(x_train.shape[1]):\n            if(weights[j] >= 0):\n                del_weights += Lambda/x_train.shape[0]\n            else:\n                del_weights += -1*Lambda/x_train.shape[0]\n        \n        #updating value of weights and bias\n        weights -=  learning_rate * del_weights\n        bias -= learning_rate * del_bias\n        \n    return weights,bias\n","metadata":{"execution":{"iopub.status.busy":"2021-10-06T05:41:20.580803Z","iopub.execute_input":"2021-10-06T05:41:20.581108Z","iopub.status.idle":"2021-10-06T05:41:20.590560Z","shell.execute_reply.started":"2021-10-06T05:41:20.581080Z","shell.execute_reply":"2021-10-06T05:41:20.589680Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def cross_validation_LR():\n    k = 10\n    foldsize = int(len(X)/k)\n    \n    train_metrics  = np.zeros(4)\n    test_metrics = np.zeros(4)\n    \n    for i in range(k):\n        xtest = X[i*foldsize:(i+1)*foldsize]\n        ytest = Y[i*foldsize:(i+1)*foldsize]\n        xtrain = np.concatenate((X[0:i*foldsize], X[(i+1)*foldsize:]))\n        ytrain = np.concatenate((Y[0:i*foldsize], Y[(i+1)*foldsize:]))\n        \n        w,b = fit(xtrain,ytrain,0.1,100000)\n        temp = np.array(test(xtrain , ytrain , w, b))\n        train_metrics = train_metrics + temp\n        \n        temp = np.array(test(xtest , ytest , w, b))\n        test_metrics = train_metrics + temp\n        \n    return train_metrics/k, test_metrics/k\n        \ntrain_met ,test_met = cross_validation_LR()\nprint(\"Train data metrics for Linear Regression without regularization\")\nprint(f\"MSE : {train_met[0]} , MPE : {train_met[1]} , R2 : {train_met[2]} , R2 adjusted : {train_met[3]}\")\nprint(\"Test data metrics for Linear Regression without regularization\")\nprint(f\"MSE : {test_met[0]} , MPE : {test_met[1]} , R2 : {test_met[2]} , R2 adjusted : {test_met[3]}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T06:15:34.374321Z","iopub.execute_input":"2021-10-06T06:15:34.374636Z","iopub.status.idle":"2021-10-06T06:16:08.986909Z","shell.execute_reply.started":"2021-10-06T06:15:34.374596Z","shell.execute_reply":"2021-10-06T06:16:08.985981Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"def cross_validation_ridge():\n    k = 10\n    foldsize = int(len(X)/k)\n    \n    train_metrics  = np.zeros(4)\n    test_metrics = np.zeros(4)\n    \n    for i in range(k):\n        xtest = X[i*foldsize:(i+1)*foldsize]\n        ytest = Y[i*foldsize:(i+1)*foldsize]\n        xtrain = np.concatenate((X[0:i*foldsize], X[(i+1)*foldsize:]))\n        ytrain = np.concatenate((Y[0:i*foldsize], Y[(i+1)*foldsize:]))\n        \n        w,b = fit_ridge(xtrain,ytrain,0.1,100000, 0.1)\n        temp = np.array(test(xtrain , ytrain , w, b))\n        train_metrics = train_metrics + temp\n        \n        temp = np.array(test(xtest , ytest , w, b))\n        test_metrics = train_metrics + temp\n        \n    return train_metrics/k, test_metrics/k\n        \ntrain_met ,test_met = cross_validation_ridge()\nprint(\"Train data metrics for Linear Regression with ridge regularization\")\nprint(f\"MSE : {train_met[0]} , MPE : {train_met[1]} , R2 : {train_met[2]} , R2 adjusted : {train_met[3]}\")\nprint(\"Test data metrics for Linear Regression with ridge regularization\")\nprint(f\"MSE : {test_met[0]} , MPE : {test_met[1]} , R2 : {test_met[2]} , R2 adjusted : {test_met[3]}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T06:34:37.645395Z","iopub.execute_input":"2021-10-06T06:34:37.645656Z","iopub.status.idle":"2021-10-06T06:35:15.462881Z","shell.execute_reply.started":"2021-10-06T06:34:37.645629Z","shell.execute_reply":"2021-10-06T06:35:15.461916Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"def cross_validation_lasso():\n    k = 10\n    foldsize = int(len(X)/k)\n    \n    train_metrics  = np.zeros(4)\n    test_metrics = np.zeros(4)\n    \n    for i in range(k):\n        xtest = X[i*foldsize:(i+1)*foldsize]\n        ytest = Y[i*foldsize:(i+1)*foldsize]\n        xtrain = np.concatenate((X[0:i*foldsize], X[(i+1)*foldsize:]))\n        ytrain = np.concatenate((Y[0:i*foldsize], Y[(i+1)*foldsize:]))\n        \n        w,b = fit_lasso(xtrain,ytrain,0.1,100000, 0.1)\n        temp = np.array(test(xtrain , ytrain , w, b))\n        train_metrics = train_metrics + temp\n        \n        temp = np.array(test(xtest , ytest , w, b))\n        test_metrics = train_metrics + temp\n        \n    return train_metrics/k, test_metrics/k\n        \ntrain_met ,test_met = cross_validation_lasso()\nprint(\"Train data metrics for Linear Regression with lasso regularization\")\nprint(f\"MSE : {train_met[0]} , MPE : {train_met[1]} , R2 : {train_met[2]} , R2 adjusted : {train_met[3]}\")\nprint(\"Test data metrics for Linear Regression with lasso regularization\")\nprint(f\"MSE : {test_met[0]} , MPE : {test_met[1]} , R2 : {test_met[2]} , R2 adjusted : {test_met[3]}\")","metadata":{"execution":{"iopub.status.busy":"2021-10-06T06:35:36.521847Z","iopub.execute_input":"2021-10-06T06:35:36.522121Z","iopub.status.idle":"2021-10-06T06:36:24.063514Z","shell.execute_reply.started":"2021-10-06T06:35:36.522095Z","shell.execute_reply":"2021-10-06T06:36:24.062489Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"We can notice Mean Percentage Error was higher on test data than train data indicating overfitting. Regularization reduced MPE on test data. Ridge regression performed better overall","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:46:36.148163Z","iopub.execute_input":"2021-09-22T08:46:36.148589Z","iopub.status.idle":"2021-09-22T08:46:36.160447Z","shell.execute_reply.started":"2021-09-22T08:46:36.148544Z","shell.execute_reply":"2021-09-22T08:46:36.159155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-04T12:15:29.092176Z","iopub.execute_input":"2021-10-04T12:15:29.092451Z","iopub.status.idle":"2021-10-04T12:15:29.135597Z","shell.execute_reply.started":"2021-10-04T12:15:29.092424Z","shell.execute_reply":"2021-10-04T12:15:29.134616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}